{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perguntas: \n",
    "1-número de fatalidades tem diminuido com os anos? *procure pelas colunas de fataliade\n",
    "2-durante a noite há mais ocorrências (18:00 a 05:00)?\n",
    "3-algumas regiões tem mais ocorrências que outras?\n",
    "4-Verificar em quantas cidades já aconteceram ocorrências?\n",
    "5-alguns operadores têm mais ocorrências que outros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, when, hour\n",
    "spark = SparkSession.builder.appName(\"MeuApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ocorrencias = spark.read.option(\"delimiter\", \";\").option(\"header\", True).csv(\"ocorrencia.csv\")\n",
    "df_ocorrencias.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_municipios = spark.read.option(\"delimiter\", \",\").option(\"header\", True).csv(\"municipios.csv\")\n",
    "df_municipios.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+-------------------+--------+---------+------------+\n",
      "|codigo_uf|uf |nome               |latitude|longitude|regiao      |\n",
      "+---------+---+-------------------+--------+---------+------------+\n",
      "|11       |RO |Rondônia           |-10.83  |-63.34   |Norte       |\n",
      "|12       |AC |Acre               |-8.77   |-70.55   |Norte       |\n",
      "|13       |AM |Amazonas           |-3.47   |-65.1    |Norte       |\n",
      "|14       |RR |Roraima            |1.99    |-61.33   |Norte       |\n",
      "|15       |PA |Pará               |-3.79   |-52.48   |Norte       |\n",
      "|16       |AP |Amapá              |1.41    |-51.77   |Norte       |\n",
      "|17       |TO |Tocantins          |-9.46   |-48.26   |Norte       |\n",
      "|21       |MA |Maranhão           |-5.42   |-45.44   |Nordeste    |\n",
      "|22       |PI |Piauí              |-6.6    |-42.28   |Nordeste    |\n",
      "|23       |CE |Ceará              |-5.2    |-39.53   |Nordeste    |\n",
      "|24       |RN |Rio Grande do Norte|-5.81   |-36.59   |Nordeste    |\n",
      "|25       |PB |Paraíba            |-7.28   |-36.72   |Nordeste    |\n",
      "|26       |PE |Pernambuco         |-8.38   |-37.86   |Nordeste    |\n",
      "|27       |AL |Alagoas            |-9.62   |-36.82   |Nordeste    |\n",
      "|28       |SE |Sergipe            |-10.57  |-37.45   |Nordeste    |\n",
      "|29       |BA |Bahia              |-13.29  |-41.71   |Nordeste    |\n",
      "|31       |MG |Minas Gerais       |-18.1   |-44.38   |Sudeste     |\n",
      "|32       |ES |Espírito Santo     |-19.19  |-40.34   |Sudeste     |\n",
      "|33       |RJ |Rio de Janeiro     |-22.25  |-42.66   |Sudeste     |\n",
      "|35       |SP |São Paulo          |-22.19  |-48.79   |Sudeste     |\n",
      "|41       |PR |Paraná             |-24.89  |-51.55   |Sul         |\n",
      "|42       |SC |Santa Catarina     |-27.45  |-50.95   |Sul         |\n",
      "|43       |RS |Rio Grande do Sul  |-30.17  |-53.5    |Sul         |\n",
      "|50       |MS |Mato Grosso do Sul |-20.51  |-54.54   |Centro-Oeste|\n",
      "|51       |MT |Mato Grosso        |-12.64  |-55.42   |Centro-Oeste|\n",
      "|52       |GO |Goiás              |-15.98  |-49.86   |Centro-Oeste|\n",
      "|53       |DF |Distrito Federal   |-15.83  |-47.86   |Centro-Oeste|\n",
      "+---------+---+-------------------+--------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_estados = spark.read.option(\"delimiter\",\",\").option(\"header\",True).csv(\"estados.csv\")\n",
    "df_estados.show(truncate=False, n=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pergunta 2:\n",
    "Durante a noite há mais ocorrências (18:00 a 05:00)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir uma função que verifica o período do dia\n",
    "def periodo_dia(hora_col):\n",
    "    return F.when(\n",
    "        hora_col.isNull(), F.lit(None)\n",
    "    ).when(\n",
    "        (hora_col >= 18) | (hora_col < 5), F.lit('noite')\n",
    "    ).otherwise(F.lit('dia'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar a nova coluna 'Periodo_do_Dia' baseada na coluna 'Hora_da_Ocorrencia'\n",
    "df_ocorrencias = df_ocorrencias.withColumn('Periodo_do_Dia', periodo_dia(F.hour('Hora_da_Ocorrencia')))\n",
    "\n",
    "# Mostrar o DataFrame resultante\n",
    "#df_ocorrencias = df_ocorrencias.select(\"Numero_da_Ocorrencia\",\"Classificacao_da_Ocorrencia\",\"Hora_da_Ocorrencia\",\"Periodo_do_Dia\")\n",
    "df_ocorrencias.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_periodoDia = df_ocorrencias.groupBy(\"Periodo_do_Dia\").agg(F.count(F.col(\"Periodo_do_Dia\")).alias(\"Total\"))\n",
    "df_periodoDia.filter((F.col(\"Periodo_do_Dia\") != \"NULL\")).show(truncate=False)\n",
    "#df_periodoDia.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pergunta 3:\n",
    "Algumas regiões tem mais ocorrências que outras?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+\n",
      "|      Regiao|Qtd_ocorrencias|\n",
      "+------------+---------------+\n",
      "|    Nordeste|          13221|\n",
      "|         Sul|           7113|\n",
      "|     Sudeste|          22324|\n",
      "|Centro-Oeste|           7752|\n",
      "|       Norte|          10311|\n",
      "+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# Realizar o join entre df_ocorrencias e df_outras_regioes baseado na coluna \"Regiao\"\n",
    "df_joined = df_ocorrencias.join(df_estados, \"Regiao\", \"inner\")\n",
    "\n",
    "# Agora, realizar a agregação no DataFrame resultante do join\n",
    "df_regioes = df_joined.groupBy(\"Regiao\").agg(F.count(F.col(\"Regiao\")).alias(\"Qtd_ocorrencias\"))\n",
    "\n",
    "# Exibir o resultado\n",
    "df_regioes.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
